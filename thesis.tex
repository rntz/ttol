\documentclass[11pt]{article}

\usepackage[letterpaper,top=1in,bottom=1in,left=1in,right=1in]{geometry}

\usepackage{amsmath,amssymb}
\usepackage{array}
\usepackage{color}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{latexsym}           %for \Box
\usepackage{multicol}
\usepackage{url}

\usepackage{proof}
\usepackage{notation}

\newcommand{\bscolor}{blue}
\newcommand{\bs}[1]{\textcolor{\bscolor}{#1}}

\newcommand{\todo}[1]{\textcolor{red}{\small TODO: #1}}

\title{A Type Theory for Linking\\{\large (rough draft)}}
\author{Michael Arntzenius\\advised by Karl Crary}


\begin{document}

\maketitle

% {\small Parts of this paper which are as yet unproven and/or unimplemented
%   are in \bs{\bscolor}.}

% TODO: abstract goes here.

\section{Audience}

This paper is written assuming a working knowledge of the basics of programming
language syntax and semantics. Backus-Naur Form (BNF) is used to define grammars
and natural-deduction style inference rules are used to define logical
judgments. Familiarity with typed $\lambda$-calculi, in particular features such
as product, universal, and recursive types, is assumed. The Curry-Howard
correspondence is employed without remark throughout. Other concepts, such as
modal logic, the adjoint calculus, and hereditary substitution, are explained
before use. Prior knowledge of these is not necessary.

% FIXME: Note re understanding linking & loading.

% Detailed knowledge of the usual implementations of the processes of linking
% and loading programs is not required; the purpose of these processes, however,
% informs the motivation of this paper.

% % FIXME: phrasing
% Knowledge of the purpose (though not the implementation) of the processes of
% linking and loading programs is required to understand the motivation of this
% paper.


\section{Motivation}

Most formal literature on programming languages accounts for three processes:
parsing, typechecking and execution. Even the ubiquitous process of compilation
generally takes us outside the formal realm; the target language is typically
untyped, and arguing that compilation preserves the source language semantics is
done informally if at all. Fortunately, there is active research in this area,
in the form of verified compilers, typesafe assembly languages, and
proof-carrying code. However, there are two processes almost as ubiquitous as
compilation that have been mostly ignored by formal efforts: linking and
loading.

We define the \llib{}-calculus, showing how a typed language with explicit
support for linking and loading may be formalized and implemented.
% TODO: stuff about CAM^lib. para break.
% This sentence has too many commas.
Aside from the straightforward goal of filling a gap in our formal understanding
of computation, we are particularly motivated by the need of ConcertOS, a
project to build a typesafe operating system, for a model of linking and
loading. The content of this work is, however, not specific to ConcertOS.


% TODO: citations? refer to typed modular assembly stuff?

% Our model of static versus dynamic linking versus dynamic loading:
% static linking program P against lib A:
% - write P as lib with dep on lib A
% - run small program that loads P, loads A, links them (lib(P A)),
%   and writes the resulting no-deps library P' out to disk.
% - P' is our program.
%
% dynamic linking program P against lib A:
% - write P as lib with dep on lib A
% - write small program that loads P, loads A, links them (lib(P A)),
%   and runs resulting program.
%   is this really the correct view of things?
%
% dynamic loading:
% - load u = read("A.so") in P


\section{Background}

\subsection{Modal logic and mobility}

We initially expected to use some variety of \emph{modal logic} as our
typesystem. Modal logics are a family of logics which deal with the concept of
\emph{necessity}\footnote{And its dual, \emph{possibility}, which we do not
  consider here}. ``Necessity'' is understood in terms of ``possible worlds''.
In general, a proposition may be true in one possible world and false in
another. ``Necessary'' propositions are those true in \emph{all} possible
worlds. In contrast, ``contingent'' truths may only be true in ``our'' world; or
at least we only \emph{know} they are true in our world.\footnote{This is an
  extremely rough characterization, and ignores many important varieties of
  modal logic.}

% TODO: add mobile motivation section here.

Modal logic adds a unary propositional connective expressing that a proposition
$\tau$ is ``necessary'', which we write $\nec \tau$. What suggested modal logic
to us was that the $\nec$ operator has been shown to represent \emph{mobile}
types \cite{murphy2008modal}. The notion of mobile code arises in distributed
computation. In general, code in a distributed system may depend on the
resources of a particular computational node to run. ``Mobile'' code is code
that can run at any node. Modal logic models this if we let our ``possible
worlds'' be nodes: a necessary proposition is true in every world, just as
mobile code can run on any node. $\nec \tau$ is then the type of a piece of
mobile code that returns a value of type $\tau$.

Libraries are akin to mobile code: they are stored on-disk in a format portable
to any machine with the same operating system and instruction set---at least, as
long as it can supply the library's dependencies. This is the sticking point:
modal logic provides no good way to represent libraries with dependencies.
Explaining this problem requires a digression.

\subsection{Dependencies}

Suppose that $\nec \tau$ is the type of a library with \emph{no} dependencies
that contains code of type $\tau$. What then is the type of a library that
\emph{does} have a dependency? First, note that the primary operation on a
library with a dependency is linking it against a library fulfilling that
dependency.\footnote{There is also the issue of mutually dependent libraries.
  For simplicity, and because we believe that it is in practice quite feasible
  to avoid such circular dependencies, we ignore this problem entirely.} Second,
libraries with dependencies are defined in terms of the depended-upon thing, as
if it were a free variable. Together these suggest that libraries with
dependencies can be viewed as a kind of function, taking their dependency as an
argument, and returning their own contents as a result.

Consider then a library $l$ that depends on a $\tau_1$ and produces a $\tau_2$.
If libraries are functions of their dependencies, perhaps we can give $l$ the
type $\nec \tau_1 \to \nec \tau_2$? Unfortunately this does not suffice, because
it is not \emph{mobile}. $\nec \tau_1 \to \nec \tau_2$ is an ordinary function
type, and its values are not necessarily of a form that can be written to disk
and shipped between machines the way a library (even a library with as-yet
unfilled dependencies) can.

Can we fix this by adding a surrounding $\nec$, giving $l \isa \nec(\nec \tau_1
\to \nec \tau_2)$? Unfortunately, this still does not suffice. While this type
is mobile, it still uses an ordinary function as the mechanism for linking
against a dependency, which is undesirable for two reasons. First, it means that
linking, which involves calling the function contained in $l$, can have
arbitrary side-effects (eg. nontermination or malicious behavior), which is
clearly undesirable.

Second, it makes \emph{partial linking}, where we link a library against just
one of its several dependencies, impossible. Consider that curried functions
must receive their arguments \emph{in order}; given $f \isa \tau_1 \to \tau_2
\to \tau_3$ and $y \isa \tau_2$, I cannot apply $f$ to $y$ without also having
some $x \of \tau_1$. I can achieve this by creating a wrapper function:
\[ \lam{x}{\tau_1}{f \ap x \ap y} \]

However, this merely delays the actual call to $f$ until the first argument $x$
is received.\footnote{Uncurried functions $f \of \tau_1 \x \tau_2 \to \tau_3$
  exhibit a stronger version of this problem: they cannot be called until
  \emph{all} arguments are received.} If $f$ is the underlying function of a
library with two dependencies, this means we cannot do the actual work of
linking the library against its second dependency until we have its first. Real
linkers do not suffer from this problem.


\subsection{The adjoint calculus}

To deal with dependencies, we turn to Benton and Wadler's \emph{adjoint
  calculus} \cite{bentonwadler96adjoint}. Adjoint calculi are a family of
$\lambda$-calculi that can be used to ``encode'' both modal logic and other
logics such as intuitionistic linear logic. Here we concern ourselves only with
its relation to modal logic.

The adjoint calculus ``splits'' modal logic into two layers, an ``upper'' and a
``lower''. The upper layer corresponds to necessary or mobile things---for us,
libraries. The lower layer corresponds to ordinary, contingent things---for us,
an ordinary programming language to which we wish to add explicit support for
libraries. Thus we split our types into upper-layer library interfaces $I$ and
lower-layer types $\tau$; and our terms into libraries $L$ and ordinary terms
$e$. In Figure \ref{fig:adjoint} we give the syntax and relevant rules of our
version of the adjoint calculus, which we proceed to develop into the
$\llib$-calculus.

\begin{figure}[h]
  \centering
  \begin{description}
    \item[Syntax:]
    \[\begin{array}{rrclrrcl}
      \text{library contexts} & \D &::=& \ecx ~|~ \D, u \of I &
      \text{term contexts} & \G &::=& \ecx ~|~ \G, x \of \tau \\
      \text{interfaces} & I &::=& \up{\tau} ~|~ ... &
      \text{types} & \tau &::=& \dn{I} ~|~ ...\\
      \text{libraries}& L &::=& u ~|~ \code{e} ~|~ ... &
      \text{terms} & e &::=& x ~|~ \lib{L} ~|~ \use{L}\\
      &&&&&&~|~& \load{u}{e_1}{e_2} ~|~ ...\\
    \end{array}\]
  \item[Judgments:]\ $\D \ent L \isa I$ \ and
    \ $\D;\G \ent e \isa \tau$
  \item[Rules:]
    \[
    \infer[\upI]{\D \ent \code{e} \isa \up{\tau}}{
      \D;\ecx \ent e \isa \tau}
    \qquad
    \infer[\upE]{\D;\G \ent \use{L} \isa \tau}{
      \D \ent L \isa \up{\tau}}
    \]
    \[
    \infer[\dnI]{\D;\G \ent \lib{L} \isa \dn{I}}{
      \D \ent L \isa I}
    \qquad
    \infer[\dnE]{\D;\G \ent \load{u}{e_1}{e_2} \isa \tau}{
      \D;\G \ent e_1 \isa \dn{I} &
      \D,u \of I;\G \ent e_2 \isa \tau}
    \]
  \end{description}

  \caption{Syntax and typing rules of an adjoint calculus for libraries}
  \label{fig:adjoint}

\end{figure}

In place of the singular modal operator $\nec$, we have two operators. The
first, $\up{\tau} \in I$, injects terms into the library layer; it is the
interface of a library containing code of type $\tau$. The second, $\dn{I}$,
injects libraries into the term layer; it is the type of a run-time reference to
a library with interface $I$. Thus the modal $\nec \tau$ becomes
$\dn{\up{\tau}}$: the type of a run-time reference to a library containing code
of type $\tau$.

As we have two layers, we also have two contexts: $\D$ for library variables and
$\G$ for term variables. Terms may depend on libraries, so the typing judgment
$\D;\G \ent e \isa \tau$ for terms involves both contexts. However, the typing
judgment $\D \ent L \isa I$ for libraries lacks a term context, preventing
libraries from depending on arbitrary run-time values. Thus, to embed code into
a library via the $\ms{code}$ operator (the $\upI$ rule), it must typecheck with
an empty term context; and when embedding a library in a program via the
$\ms{lib}$ operator (the $\dnI$ rule), we throw away our $\G$ context. The
$\upE$ rule is straightforward: if we have a library $L \isa \up{\tau}$
containing code of type $\tau$, we can \ms{use} it within a program to retrieve
the embedded $\tau$. $\dnE$ is only slightly more subtle: given $e_1 \isa
\dn{I}$, which evaluates to a reference to a library with interface $I$, we can
bind a library variable $u \of I$ to the library it refers to to.

% TODO: aside re why \dnE{} has to be a large elim rule?


\subsubsection{Extending the library layer}

The only library-layer type operator \emph{needed} to encode modal $\nec$ is
$\up{\tau}$. But having separated the two layers, we are free to add other
operators to $I$. It is this expressiveness that suits the adjoint calculus to
our purposes: library-layer operators let us express the the ``super-structure''
of a library, beyond merely the type of the code it contains, in a way that
modal logic cannot. In particular, we can express dependencies as
\emph{library-layer} functions, distinct from ordinary term-layer functions:
\begin{align*}
  I &::= ... ~|~ I \to I\\
  L &::= ... ~|~ \lam{u}{I}{L} ~|~ L \ap L
\end{align*}
This cleanly separates the library-level (\emph{link-time}) computation of
linking a library against its dependencies from ordinary (\emph{run-time})
function application. We can thus avoid arbitrary link-time side-effects by
simply not introducing any side-effectful operations to the library layer.
Partial linking, as we shall see, is more complicated, but still feasible.

In general, by adding library layer operators, we express that these correspond
to the structure of the library \emph{itself}, not the code it contains. For a
concrete example of this distinction, let us first add library products:
\begin{align*}
  I &::= ... ~|~ I \x I\\
  L &::= ... ~|~ \<L, L\> ~|~ \proj{i}{L}
\end{align*}

Now, consider the following C-language header files:
\begin{center}
  \begin{tabular}{l|l}
    \emph{File:} \texttt{A.h} & \emph{File:} \texttt{B.h}\\\hline
    \begin{minipage}[t]{0.35\linewidth}
\begin{verbatim}
int x;
int y;
\end{verbatim}
    \end{minipage} &
    \begin{minipage}[t]{0.35\linewidth}
\begin{verbatim}
struct { int x; int y; } p;
\end{verbatim}
    \end{minipage}
  \end{tabular}
\end{center}

A library implementing the interface expressed by \texttt{A.h} will contain two
labels, each of type \texttt{int}. A library implementing \texttt{B.h} will
contain one label of type \texttt{struct \{int x; int y;\}} (in other words, a
pair of \texttt{int}s). The interface of \texttt{A.h} is thus best represented
by $\up{\ms{int}} \x \up{\ms{int}}$ (involving a library-layer product), while
\texttt{B.h}'s interface is $\up{\ms{int} \x \ms{int}}$ (involving a term-layer
product).


\subsubsection{Polymorphism}

Before presenting the full $\llib$-calculus, one complication remains. The
adjoint calculus we have presented so far lacks parametric polymorphism, the
ability to universally quantify over types. Adding polymorphism introduces a new
context $\Psi$ for type variables (see Figure \ref{fig:polymorph}), which raises
the question of how this context should behave in our two-layer system: Is
$\Psi$ discarded like $\G$ when we move into the library layer, or preserved
like $\D$? That is, is the typing judgment for libraries of the form $\Psi;\D
\ent L \isa I$ or does it remain $\D \ent L \isa I$?

For the sake of expressivity, we'd like to choose the former and preserve $\Psi$
in the library layer, otherwise it becomes impossible to implement a function
with a type such as $\fa{\alpha}{\dn{\up{\alpha}} \to \alpha}$. Since types
$\tau$ are conceptually lower-layer things, however, it's not immediately
obvious that this is safe. Luckily it turns out that it is.
\todo{Forward-reference safety theorems.}

\todo{Need advice on what to say here. Should we discuss in depth the
  implications for implementations re: type-passing \& monomorphism, or merely
  note them in passing?}

% NOTE: I think that actually the reason this is a sticking point is because
% polymorphism *IS* one of those things where it's not clear whether it should
% be implemented in the library or term layers. eg. you can make \Lam a
% library-layer operator, which makes type-specialization a link-time operation:
% this corresponds, I think, to monomorphisation.
%
% Worth at least noting this as future work.

\begin{figure}
  \centering
  \[\begin{array}{rrcl}
    \text{type contexts} & \Phi &::=& \ecx ~|~ \Phi, \alpha\\
    \text{types} & \tau &::=& ... ~|~ \alpha\\
    \text{terms} & e &::=& ... ~|~ \Lam{\alpha}{e} ~|~ \Ap{e}{\tau}
  \end{array}\]
  \caption{Adding polymorphism to the adjoint calculus}
  \label{fig:polymorph}
\end{figure}


\section{The $\llib$-calculus}

The $\llib$ calculus is a polymorphic adjoint calculus with functions and
products at the library layer, and functions, universals, and recursive types at
the term layer. The library operators we have discussed already; the term
operators were chosen to make the term layer Turing-complete with a minimum of
bother, the better to model a real programming language and so serve as a proof
of concept. The syntax and typing rules are given in Figure \ref{fig:llib}.

\begin{figure}[p]
  \centering
  \begin{description}
  \item[Syntax:]
    \[\begin{array}{rrcl}
      \text{interfaces} & I &::=& \up{\tau} ~|~ I \to I ~|~ I \x I\\
      \text{types} & \tau &::=&
      \dn{I} ~|~ \tau \to \tau ~|~ \alpha ~|~ \fa{\alpha}{\tau}
      ~|~ \trec{\alpha}{\tau}\\
      \text{libraries} & L &::=&
      u ~|~ \lam{u}{I}{L} ~|~ L \ap L ~|~ \<L,L\> ~|~ \proj{i}{L}
      ~|~ \code{e}\\
      \text{terms} & e &::=&
      x ~|~ \lam{x}{\tau}{e} ~|~ e \ap e
      ~|~ \Lam{\alpha}{e} ~|~ \Ap{e}{\tau}
      ~|~ \roll{\alpha}{\tau}{e} ~|~ \unroll{e}\\
      &&~|~& \lib{L} ~|~ \use{L} ~|~ \load{u}{e}{e}
    \end{array}\]
  \item[Judgments:]\[
    \begin{array}[]{lll}
      \Psi \ent I \isiface &\quad \Psi;\D \ent L \isa I &\quad L \isval\\
      \Psi \ent \tau \istype &\quad \Psi;\D;\G \ent e \isa \tau &\quad e \isval
    \end{array}\]
  \item[Rules:]
    \[
    \infer{\Psi, \alpha, \Psi' \ent \alpha \istype}{} \qquad
    \infer{\Psi \ent \dn{I} \istype}{\Psi \ent I \isiface} \qquad
    \infer{\Psi \ent \tau_1 \to \tau_2 \istype}{
      \Psi \ent \tau_1 \istype &
      \Psi \ent \tau_2 \istype}
    \]\[
    \infer{\Psi \ent \fa{\alpha}{\tau} \istype}{
      \Psi,\alpha \ent \tau \istype} \qquad
    \infer{\Psi \ent \trec{\alpha}{\tau} \istype}{
      \Psi,\alpha \ent \tau \istype}
    \]

    \[
    \infer{\Psi \ent \up{\tau} \isiface}{\Psi \ent \tau \istype} \qquad
    \infer{\Psi \ent I_1 \to I_2 \isiface}{
      \Psi \ent I_1 \isiface &
      \Psi \ent I_2 \isiface} \qquad
    \infer{\Psi \ent I_1 \x I_2 \isiface}{
      \Psi \ent I_1 \isiface &
      \Psi \ent I_2 \isiface}
    \]

    \[
    \infer{\Psi; \D, u \of I, \D' \ent u \isa I}{}
    \]\[
    \infer{\Psi; \D \ent \lam{u}{I_1}{L} \isa I_1 \to I_2}{
      \Psi;\D, u \of I_1 \ent L \isa I_2} \qquad
    \infer{\Psi; \D \ent L_1 \ap L_2 \isa I_2}{
      \Psi;\D \ent L_1 \isa I_1 \to I_2 &
      \Psi;\D \ent L_2 \isa I_1}
    \]\[
    \infer{\Psi; \D \ent \<L_1, L_2\> \isa I_1 \x I_2}{
      \Psi; \D \ent L_1 \isa I_1 &
      \Psi; \D \ent L_2 \isa I_2} \qquad
    \infer{\Psi; \D \ent \proj{i}{L} \isa I_i}{
      \Psi;\D \ent L \isa I_1 \x I_2}
    \]\[
    \infer{\Psi;\D \ent \code{e} \isa \up{\tau}}{
      e \isval &
      \Psi;\D;\ecx \ent e \isa \tau} \qquad
    \infer{\Psi;\D;\G \ent \use{L} \isa \tau}{
      \Psi;\D \ent L \isa \up{\tau}}
    \]

    \[
    \infer{\Psi;\D;\G, x \of \tau, \G' \ent x \isa \tau}{}
    \]\[
    \infer{\Psi;\D;\G \ent \lam{x}{\tau_1}{e} \isa \tau_1 \to \tau_2}{
      \Psi;\D;\G, x \of \tau_1 \ent e \isa \tau_2} \qquad
    \infer{\Psi;\D;\G \ent e_1 \ap e_2 \isa \tau_2}{
      \Psi;\D;\G \ent e_1 \isa \tau_1 \to \tau_2 &
      \Psi;\D;\G \ent e_2 \isa \tau_1}
    \]\[
    \infer{\Psi;\D;\G \ent \Lam{\alpha}{e} \isa \fa{\alpha}{\tau}}{
      \Psi,\alpha;\D;\G \ent e \isa \tau} \qquad
    \infer{\Psi;\D;\G \ent \Ap{e}{\tau'} \isa \sub{\tau'}{\alpha}{\tau}}{
      \Psi \ent \tau' \istype &
      \Psi;\D;\G \ent e \isa \fa{\alpha}{\tau}}
    \]\[
    \infer{\Psi;\D;\G \ent \roll{\alpha}{\tau}{e} \isa \trec{\alpha}{\tau}}{
      \Psi;\D;\G \ent e \isa \sub{\trec{\alpha}{\tau}}{\alpha}{\tau}}
    \qquad
    \infer{\Psi;\D;\G \ent \unroll{e} \isa \sub{\trec{\alpha}{\tau}}{\alpha}{\tau}}{
      \Psi;\D;\G \ent e \isa \trec{\alpha}{\tau}}
    \]\[
    \infer{\Psi;\D;\G \ent \lib{L} \isa \dn{I}}{\Psi;\D \ent L \isa I} \qquad
    \infer{\Psi;\D;\G \ent \use{L} \isa \tau}{\Psi;\D \ent L \isa \up{\tau}}
    \qquad
    \infer{\Psi;\D;\G \ent \load{u}{e_1}{e_2} \isa \tau}{
      \Psi;\D;\G \ent e_1 \isa \dn{I} &
      \Psi;\D, u \of I; \G \ent e_2 \isa \tau}
    \]

    \[
    \infer{\lam{x}{\tau}{e} \isval}{} \qquad
    \infer{\Lam{\alpha}{e} \isval}{} \qquad
    \infer{\roll{\alpha}{\tau}{e} \isval}{e \isval} \qquad
    \infer{\lib{L} \isval}{L \isval}
    \]
    \[
    \infer{u \isval}{} \qquad
    \infer{\lam{u}{I}{L} \isval}{} \qquad
    \infer{\<L_1, L_2\> \isval}{L_1 \isval & L_2 \isval} \qquad
    \infer{\code{e} \isval}{e \isval}
    \]

  \end{description}

  \caption{Syntax and typing rules of the $\llib$-calculus}
  \label{fig:llib}
\end{figure}


\subsection{Suspensions versus values}

Careful inspection of Figure \ref{fig:llib} reveals the unusual judgment $e
\valish$. This is meant to convey that $e$ is close enough to a value as makes
no difference. The troubling rule here (the reason we don't just call it $e
\isval$) is the axiom $\lib{L} \valish$, which puts no constraints on the form
of $L$. We'll see why this is acceptable later; for now, $e \valish$ may be read
as if it said ``$e$ is a value''.

$e \valish$ notably makes an appearance as a premise of the $\upI$ rule:
\[
\infer{\Psi;\D \ent \code{e} \isa \up{\tau}}{
  e \valish &
  \Psi;\D;\ecx \ent e \isa \tau}
\]

In contrast with the adjoint calculus presented so far, the $\llib$-calculus
requires that in the library $\code{e}$, the enclosed term $e$ be a value.
Without this constraint, we are forced to make an ugly choice: either evaluating
a library term $L$ may involve evaluating embedded terms $e$, bringing back the
danger of unrestricted side-effects during linking; or, we must take $\code{e}$
to be a \emph{suspension} that delays evaluating $e$ until it is extracted
via $\ms{use}$. The former is clearly unacceptable. The latter is a principled
solution, but fails to capture the semantics of real-world libraries. We
therefore add the $e \valish$ restriction, on the grounds that it better models
real-world semantics at a neglible cost to expressivity.
% TODO: footnote re if you want suspensions, just use a function


\subsection{Dynamic semantics, partial linking, and hereditary substitution}

As yet we have not presented dynamic semantics for the $\llib$-calculus. The
primary difficulty in constructing such a semantics is accounting for partial
linking: the ability to link a library with multiple dependencies against any
one of them independently. Since we are representing libraries as functions of
their dependencies, this reduces to the problem of \emph{partial evaluation}:
reducing a function applied to some known and some unknown arguments to a
function of only the unknown arguments.

% The insight is that "function applied to some known & some unknown args" can
% be reduced to "term with substitutions for some but not all of its free vars"

% \[\begin{array}{rcl}
%   M &::=& \at{R} ~|~ \lam{u}{I}{M} ~|~ \<M,M\> ~|~ \code{e}\\
%   R &::=& u ~|~ R \ap M ~|~ \proj{i}{R}\\
%   e &::=& ... ~|~ \lib{M} ~|~ \use{R}
% \end{array}\]

% Consider a library $L \isa I_1 \to I_2 \to I_3$ with two dependencies,
% $I_1$ and $I_2$. Syntactically we treat this as a curried function of two
% arguments, which requires it to be applied to its dependencies in order, but we
% would like to be able to apply it to either dependency without yet having the
% other, and still reduce the resulting term. In other words, given some $L_2 \isa
% I_2$,
% \[ \lam{u}{I_1}{L \ap u \ap L_2} \]
% should be a reducible expression!

% The ability to reduce a partially applied function in this manner is known in
% the field of compiler optimization as \emph{partial evaluation}. 

Partial evaluation is usually considered in the context of compiler
optimization, but unfortunately we do not have the luxury of treating it as a
mere optimization. Luckily, there is a standard technique for achieving this,
known as \emph{hereditary substitution}. Hereditary substitution can intuitively
be thought of as keeping all terms ``as normalized as possible given their free
variables'' at all times. As such, all the actual work of reduction in a system
of hereditary substitution occurs during substitution---when we eliminate free
variables.

Hereditary substitution separates terms into ``canonical'' and ``atomic'' forms.
In our case, we separate libraries $L$ into canonical $M$ and atomic $R$. We
present the resulting $\llhs$-calculus. Canonical libraries $M$ are either
introduction forms ($\lam{u}{I}{M}$, $\<M,M\>$, $\code{e}$) or embedded atomic
forms ($\at{R}$). Atomic forms $R$ consist of a series of elimination forms ($R
\ap M$, $\proj{i}{M}$) applied to a ``head'' variable ($u$). Directly replacing
this head variable with a canonical term, as in na\"ive substitution, would be
syntactically invalid. Thus, only irreducible uses of elimination forms are
expressible.

Hereditary substitution is the algorithm by which we replace variables without
violating this syntactic constraint, and its rules are given along with the
dynamic semantics for the $\llhs$-calculus in Figure \ref{fig:llhsdynsem}.
\todo{Explain that it subsumes evaluation rules for library level; progress \&
  preservation become substitution lemmas.}

Given this, the translation from the original $\llib$-calculus into $\llhs$ is
easy to define, and it is this translation that justifies the laxness of the
judgment $e \valish$. Post-translation, $\lib{L}$ becomes $\lib{M}$, and thanks
to the syntactic restrictions of hereditary substitution, $M$ is guaranteed not
to require further reduction (modulo containing some free variables); so while
$\lib{L}$ may not \emph{be} a value, it \emph{translates} to one.


\begin{figure}
  \centering
  \begin{description}
    \item[Syntax:]
      \[\begin{array}{rrcl}
        \text{canonical libraries} &
        M &::=& \at{R} ~|~ \lam{u}{I}{M} ~|~ \<M,M\> ~|~ \code{e}\\
        \text{atomic libraries} & R &::=& u ~|~ R \ap M ~|~ \proj{i}{R}\\
        \text{terms} & e &::=& ... ~|~ \lib{M} ~|~ \use{R}
      \end{array}\]

    \item[Judgments:]\hfill\\
      $\Psi;\D \ent L \isa I$ splits into $\Psi;\D \ent M \isa I$ and $\Psi;\D
      \ent R \isa I$\\
      $e \valish$ is replaced by $e \isval$

    \item[Rules:]
      \[
      \infer{\Psi;\D;\G \ent \lib{M} \isa \dn{I}}{\Psi;\D \ent M \isa I} \qquad
      \infer{\Psi;\D;\G \ent \use{R} \isa \tau}{\Psi;\D \ent R \isa \up{\tau}}
      \]

      \[
      \infer{\Psi;\D \ent \at{R} \isa I}{\Psi;\D \ent R \isa I} \qquad
      \infer{\Psi;\D,u \of I,\D' \ent u \isa I}{} \qquad
      \infer{\Psi;\D \ent \code{e} \isa \up{\tau}}{
        e \isval &
        \Psi;\D;\ecx \ent e \isa \tau}
      \]\[
      \infer{\Psi;\D \ent \lam{u}{I_1}{M} \isa I_1 \to I_2}{
        \Psi;\D, u \of I_1 \ent M \isa I_2}
      \qquad
      \infer{\Psi;\D \ent R \ap M \isa I_2}{
        \Psi;\D \ent R \isa I_1 \to I_2 &
        \Psi;\D \ent M \isa I_1}
      \]\[
      \infer{\Psi;\D \ent \<M_1, M_2\> \isa I_1 \x I_2}{
        \Psi;\D \ent M_1 \isa I_1 &
        \Psi;\D \ent M_2 \isa I_2} \qquad
      \infer{\Psi;\D \ent \proj{i}{R} \isa I_i}{
        \Psi;\D \ent R \isa I_1 \x I_2}
      \]

      \[
      \infer{\lam{x}{\tau}{e} \isval}{} \qquad
      \infer{\Lam{\alpha}{e} \isval}{} \qquad
      \infer{\roll{\alpha}{\tau} \isval}{} \qquad
      \infer{\lib{M} \isval}{}
      \]

    \item[Translation from \llib{}:] We define an operation $\trans{\_}$ that
      takes libraries $L$ to canonical libraries $M$. We use library
      substitution, defined in Figure \ref{fig:llhsdynsem}.
      % TODO: insert ref to proof of substitution lemma.
      \begin{align*}
        \trans{I} &\in M\\
        \trans{u} &= \at{u}\\
        \trans{\lam{u}{I}{L}} &= \lam{u}{I}{\trans{L}}\\
        \trans{\<L_1, L_2\>} &= \<\trans{L_1}, \trans{L_2}\>\\
        \trans{L_1 \ap L_2} &=
        \begin{cases}
          M' & \text{if }\,\trans{L_1} = \lam{u}{I}{M}
          \text{ and } \sub{\trans{L_2}}{u}{M} \to M'\\
          \at{(R \ap \trans{L_2})} & \text{if }\,\trans{L_1} = \at{R}\\
        \end{cases}\\
        \trans{\proj{i}{L}} &=
        \begin{cases}
          M_i & \text{if }\,\trans{L} = \<M_1, M_2\>\\
          \at{(\proj{i}{R})} & \text{if }\,\trans{L} = \at{R}
        \end{cases}
      \end{align*}

      % FIXME: add translation from \llib
  \end{description}

  \caption{Syntax \& typing rules of $\llhs$ (where they differ from $\llib$)
    and translation from $\llib$}
  \label{fig:llhs}
\end{figure}


\begin{figure}
  \centering
  \begin{description}
  \item[Judgments:]\hfill

    \begin{tabular}{rl}
      Library-layer:&
      $\sub{M}{u}{M} \to M$, \ $\sub{M}{u}{R} \to M$, \ $\sub{M}{u}{e} \to e$\\
      Term-layer:& $e \step e$
    \end{tabular}

  \item[Substitution rules:]
    \[
    \infer{\sub{M}{u}{\at{R}} \to N}{\sub{M}{u}{R} \to N} \qquad
    \infer{\sub{M}{u}{\code{e}} \to \code{e'}}{
      \sub{M}{u}{e} \to e'}
    \]\[
    \infer{\sub{M}{u}{\lam{v}{I}{N}} \to \lam{v}{I}{N'}}{
      \sub{M}{u}{N} \to N' &
      (u \ne v)} \qquad
    \infer{\sub{M}{u}{\<M_1, M_2\>} \to \<M_1', M_2'\>}{
      \sub{M}{u}{M_1} \to M_1' &
      \sub{M}{u}{M_1} \to M_2'}
    \]

    \[
    \infer{\sub{M}{u}{u} \to M}{} \qquad
    \infer{\sub{M}{u}{v} \to \at{v}}{(u \ne v)}
    \]\[
    \infer{\sub{M}{u}{R \ap N} \to \at{R' \ap N'}}{
      \sub{M}{u}{R} \to \at{R'} &
      \sub{M}{u}{N} \to N'}
    \qquad
    \infer{\sub{M}{u}{\proj{i}{R}} \to \proj{i}{R'}}{
      \sub{M}{u}{R} \to \at{R'}
    }
    \]\[
    \infer{\sub{M}{u}{R \ap N} \to O'}{
      \sub{M}{u}{R} \to \lam{v}{I}{O} &
      \sub{M}{u}{N} \to N' &
      \sub{N}{v}{O} \to O'}
    \qquad
    \infer{\sub{M}{u}{\proj{i}{R}} \to M_i}{
      \sub{M}{u}{R} \to \<M_1, M_2\>}
    \]

    \[
    \infer{\sub{M}{u}{\lib{N}} \to \lib{N'}}{
      \sub{M}{u}{N} \to N'}
    \qquad
    \infer{\sub{M}{u}{\use{R}} \to \use{R'}}{
      \sub{M}{u}{R} \to \at{R'}}
    \qquad
    \infer{\sub{M}{u}{\use{R}} \to e}{\sub{M}{u}{R} \to \code{e}}
    \]

    (All other $\sub{M}{u}{e} \to e$ rules just distribute the substitution
    across subexpressions.)

  \item[Evaluation rules:]
    \[
    \infer{e_1 \ap e_2 \step e_1' \ap e_2}{e_1 \step e_1'} \qquad
    \infer{e_1 \ap e_2 \step e_1 \ap e_2'}{e_1 \isval & e_2 \step e_2'} \qquad
    \infer{(\lam{x}{\tau}{e_1}) \ap e_2 \step \sub{e_2}{x}{e_1}}{}
    \]\[
    \infer{\<e_1, e_2\> \step \<e_1', e_2\>}{e_1 \step e_1'} \qquad
    \infer{\<e_1, e_2\> \step \<e_1, e_2'\>}{e_1 \isval & e_2 \step e_2'} \qquad
    \infer{\proj{i}{e} \step \proj{i}{e'}}{e \step e'} \qquad
    \infer{\proj{i}{\<e_1, e_2\>} \step e_i}{e_1 \isval & e_2 \isval}
    \]\[
    \infer{\Ap{e}{\tau} \step \Ap{e'}{\tau}}{e \step e'} \qquad
    \infer{\Ap{(\Lam{\alpha}{e})}{\tau} \step \sub{\tau}{\alpha}{e}}{}
    \]\[
    \infer{\roll{\alpha}{\tau}{e} \step \roll{\alpha}{\tau}{e'}}{e \step e'} \qquad
    \infer{\unroll{e} \step \unroll{e'}}{e \step e'} \qquad
    \infer{\unroll{(\roll{\alpha}{\tau}{e})} \step e}{e \isval}
    \]\[
    \infer{\load{u}{e_1}{e_2} \step \load{u}{e_1'}{e_2}}{e_1 \step e_1'} \qquad
    \infer{\load{u}{\lib{M}}{e_2} \step e_2'}{\sub{M}{u}{e_2} \to e_2'}
    \]
  \end{description}

  \caption{Dynamic semantics of $\llhs$}
  \label{fig:llhsdynsem}
\end{figure}

\todo{Write up proofs of progress and preservation.}


\newcommand{\camlib}{CAM\ensuremath{^{\text{lib}}}}
\section{\camlib{}}

The ``Categorical Abstract Machine'', or CAM, is a simple abstract machine used
as a compilation target for $\lambda$-calculi and other functional languages. We
extend a simplified version of the CAM with instructions that implement our
hereditary-substitution library operations. Efficient implementation requires
careful use of explicit substitutions to avoid deep-copying. \todo{}

\subsection{Instruction set}
\todo{}

\subsection{Explicit substitutions and copying concerns}
\todo{}

\subsection{Object files}
\todo{}


\section{Implementation}

We have implemented, in Standard ML, a typechecker and compiler for the
$\llib$-calculus, translating through the $\llib$-calculus with hereditary
substitution, targetting the \camlib{}. We have also implemented a bytecode
interpreter for the \camlib{} (written in C). \todo{}

Current work is at \url{https://github.com/rntz/ttol}.


\newpage
\bibliographystyle{plain}
\bibliography{thesis}

\end{document}
